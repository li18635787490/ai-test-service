"""
AI æä¾›å•†æŠ½è±¡å±‚ - æ”¯æŒå¤šç§ AI æœåŠ¡çš„ç»Ÿä¸€æ¥å£
"""
from abc import ABC, abstractmethod
from typing import Optional, List
import json

from app.config import get_settings
from app.models import CheckDimension, CheckResult, Issue, Severity


class BaseAIProvider(ABC):
    """AI æä¾›å•†åŸºç±»"""

    @abstractmethod
    async def analyze(
        self,
        content: str,
        dimension: CheckDimension,
        custom_rules: Optional[str] = None
    ) -> CheckResult:
        """åˆ†ææ–‡æ¡£å†…å®¹"""
        pass

    @abstractmethod
    async def generate_summary(
        self,
        content: str,
        results: List[CheckResult]
    ) -> str:
        """ç”Ÿæˆæ•´ä½“æ€»ç»“"""
        pass

    def _get_dimension_prompt(self, dimension: CheckDimension, custom_rules: Optional[str] = None) -> str:
        """è·å–æ£€æµ‹ç»´åº¦å¯¹åº”çš„æç¤ºè¯"""
        prompts = {
            CheckDimension.FORMAT: """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£æ ¼å¼å®¡æ ¸ä¸“å®¶ã€‚è¯·å¯¹æ–‡æ¡£è¿›è¡Œ**ä¸¥æ ¼çš„æ ¼å¼è§„èŒƒæ£€æŸ¥**ï¼Œé€æ¡æ‰¾å‡ºå…·ä½“é—®é¢˜ã€‚

## æ£€æŸ¥æ¸…å•

### 1. æ ‡é¢˜ä¸ç»“æ„
- æ ‡é¢˜å±‚çº§æ˜¯å¦æ¸…æ™°ï¼ˆä¸€çº§æ ‡é¢˜â†’äºŒçº§æ ‡é¢˜â†’ä¸‰çº§æ ‡é¢˜ï¼‰
- æ˜¯å¦å­˜åœ¨æ ‡é¢˜è·³çº§ï¼ˆå¦‚ä¸€çº§ç›´æ¥åˆ°ä¸‰çº§ï¼‰
- æ ‡é¢˜ç¼–å·æ˜¯å¦è¿ç»­ä¸€è‡´ï¼ˆ1.1, 1.2, 1.3 è¿˜æ˜¯ 1.1, 1.3, 1.5ï¼‰
- æ ‡é¢˜å­—å·/æ ·å¼æ˜¯å¦ç»Ÿä¸€

### 2. æ®µè½ä¸æ’ç‰ˆ
- æ®µè½æ˜¯å¦æœ‰åˆç†çš„é¦–è¡Œç¼©è¿›
- æ®µè½é—´è·æ˜¯å¦ä¸€è‡´
- æ˜¯å¦æœ‰è¿‡é•¿çš„æ®µè½ï¼ˆè¶…è¿‡200å­—å»ºè®®åˆ†æ®µï¼‰
- ç©ºè¡Œä½¿ç”¨æ˜¯å¦è§„èŒƒï¼ˆä¸åº”è¿ç»­å¤šä¸ªç©ºè¡Œï¼‰

### 3. åˆ—è¡¨ä¸è¡¨æ ¼
- åˆ—è¡¨ç¬¦å·æ˜¯å¦ç»Ÿä¸€ï¼ˆå…¨ç”¨â—æˆ–å…¨ç”¨-ï¼‰
- å¤šçº§åˆ—è¡¨å±‚çº§æ˜¯å¦æ¸…æ™°
- è¡¨æ ¼æ˜¯å¦æœ‰è¡¨å¤´
- è¡¨æ ¼å†…å®¹æ˜¯å¦å¯¹é½

### 4. æ ‡ç‚¹ä¸ç¬¦å·
- ä¸­è‹±æ–‡æ ‡ç‚¹æ˜¯å¦æ··ç”¨ï¼ˆå¦‚ä¸­æ–‡ç”¨è‹±æ–‡é€—å·,ï¼‰
- å¼•å·ä½¿ç”¨æ˜¯å¦æ­£ç¡®ï¼ˆ""è¿˜æ˜¯""ï¼‰
- çœç•¥å·æ˜¯å¦è§„èŒƒï¼ˆâ€¦è¿˜æ˜¯...ï¼‰
- æ•°å­—ä¸å•ä½ä¹‹é—´æ˜¯å¦æœ‰ç©ºæ ¼

### 5. å­—ä½“ä¸æ’ç‰ˆ
- æ­£æ–‡å­—ä½“æ˜¯å¦ç»Ÿä¸€
- æ˜¯å¦æœ‰ä¸å½“çš„åŠ ç²—/æ–œä½“/ä¸‹åˆ’çº¿
- è¡Œé—´è·æ˜¯å¦ä¸€è‡´
- é¡µè¾¹è·æ˜¯å¦åˆç†

## è¯„åˆ†æ ‡å‡†
- 90-100åˆ†ï¼šæ ¼å¼è§„èŒƒï¼Œæœ€å¤š1-2ä¸ªå°é—®é¢˜
- 75-89åˆ†ï¼šæœ‰ä¸€äº›æ ¼å¼é—®é¢˜ï¼Œä½†ä¸å½±å“é˜…è¯»
- 60-74åˆ†ï¼šæ ¼å¼é—®é¢˜è¾ƒå¤šï¼Œå½±å“æ–‡æ¡£ä¸“ä¸šæ€§
- 60åˆ†ä»¥ä¸‹ï¼šæ ¼å¼æ··ä¹±ï¼Œéœ€è¦å…¨é¢æ•´æ”¹
""",
            CheckDimension.CONTENT: """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹è´¨é‡å®¡æ ¸ä¸“å®¶ã€‚è¯·å¯¹æ–‡æ¡£è¿›è¡Œ**å†…å®¹è´¨é‡æ·±åº¦æ£€æŸ¥**ï¼Œæ‰¾å‡ºå…·ä½“é—®é¢˜ã€‚

## æ£€æŸ¥æ¸…å•

### 1. æ–‡å­—è´¨é‡
- æ˜¯å¦æœ‰é”™åˆ«å­—ï¼ˆå¦‚ï¼šçš„åœ°å¾—æ··ç”¨ã€å½¢è¿‘å­—é”™è¯¯ï¼‰
- æ˜¯å¦æœ‰è¯­ç—…ï¼ˆå¦‚ï¼šä¸»è¯­ç¼ºå¤±ã€æ­é…ä¸å½“ã€æˆåˆ†æ®‹ç¼ºï¼‰
- æ˜¯å¦æœ‰é‡å¤å•°å—¦çš„è¡¨è¾¾
- æ ‡ç‚¹ç¬¦å·æ˜¯å¦æ­£ç¡®ä½¿ç”¨

### 2. è¡¨è¿°æ¸…æ™°åº¦
- å¥å­æ˜¯å¦è¿‡é•¿éš¾ä»¥ç†è§£ï¼ˆè¶…è¿‡50å­—çš„é•¿å¥ï¼‰
- æ˜¯å¦æœ‰æ­§ä¹‰è¡¨è¾¾
- ä¸“ä¸šæœ¯è¯­æ˜¯å¦é¦–æ¬¡å‡ºç°æ—¶æœ‰è§£é‡Š
- ç¼©å†™è¯æ˜¯å¦æœ‰è¯´æ˜ï¼ˆé¦–æ¬¡å‡ºç°åº”å†™å…¨ç§°ï¼‰

### 3. å†…å®¹å®Œæ•´æ€§
- æ–‡æ¡£æ˜¯å¦æœ‰æ˜ç¡®çš„å¼€å¤´ã€æ­£æ–‡ã€ç»“å°¾
- é‡è¦æ¦‚å¿µæ˜¯å¦æœ‰å……åˆ†è§£é‡Š
- æ˜¯å¦æœ‰æœªå®Œæˆçš„å¥å­æˆ–æ®µè½ï¼ˆå¦‚ï¼š"å¾…è¡¥å……"ã€"TBD"ï¼‰
- å…³é”®ä¿¡æ¯æ˜¯å¦é—æ¼

### 4. è¯­è¨€é£æ ¼
- è¯­æ°”æ˜¯å¦ä¸€è‡´ï¼ˆæ­£å¼/éæ­£å¼ï¼‰
- äººç§°æ˜¯å¦ç»Ÿä¸€ï¼ˆç¬¬ä¸€äººç§°/ç¬¬ä¸‰äººç§°ï¼‰
- æ—¶æ€æ˜¯å¦ä¸€è‡´
- ä¸­è‹±æ–‡æ··æ’æ˜¯å¦åˆç†

### 5. æ•°æ®ä¸äº‹å®
- æ•°æ®æ˜¯å¦æœ‰æ¥æºè¯´æ˜
- æ—¥æœŸæ ¼å¼æ˜¯å¦ç»Ÿä¸€
- æ•°å­—ç²¾åº¦æ˜¯å¦ä¸€è‡´ï¼ˆå¦‚å°æ•°ç‚¹ä½æ•°ï¼‰
- å•ä½æ˜¯å¦æ­£ç¡®ä¸”ä¸€è‡´

## è¯„åˆ†æ ‡å‡†
- 90-100åˆ†ï¼šå†…å®¹è´¨é‡ä¼˜ç§€ï¼Œè¡¨è¿°æ¸…æ™°å‡†ç¡®
- 75-89åˆ†ï¼šæœ‰å°‘é‡é—®é¢˜ï¼Œæ•´ä½“è´¨é‡è‰¯å¥½
- 60-74åˆ†ï¼šé—®é¢˜è¾ƒå¤šï¼Œéœ€è¦ä¿®æ”¹æ¶¦è‰²
- 60åˆ†ä»¥ä¸‹ï¼šå†…å®¹è´¨é‡å·®ï¼Œéœ€è¦é‡å†™
""",
            CheckDimension.LOGIC: """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é€»è¾‘åˆ†æä¸“å®¶ã€‚è¯·å¯¹æ–‡æ¡£è¿›è¡Œ**é€»è¾‘ä¸€è‡´æ€§æ·±åº¦æ£€æŸ¥**ï¼Œæ‰¾å‡ºçŸ›ç›¾å’Œé—®é¢˜ã€‚

## æ£€æŸ¥æ¸…å•

### 1. å‰åä¸€è‡´æ€§
- åŒä¸€æ¦‚å¿µçš„æè¿°æ˜¯å¦å‰åä¸€è‡´
- æ•°æ®å¼•ç”¨æ˜¯å¦å‰åçŸ›ç›¾
- æ—¶é—´çº¿æ˜¯å¦åˆç†ï¼ˆä¸åº”å‡ºç°æ—¶é—´å€’æµï¼‰
- äººç‰©/è§’è‰²æè¿°æ˜¯å¦ä¸€è‡´

### 2. å› æœé€»è¾‘
- å› æœå…³ç³»æ˜¯å¦æˆç«‹
- è®ºè¯è¿‡ç¨‹æ˜¯å¦å……åˆ†
- ç»“è®ºæ˜¯å¦æœ‰è¶³å¤Ÿçš„å‰ææ”¯æ’‘
- æ˜¯å¦å­˜åœ¨é€»è¾‘è·³è·ƒ

### 3. æ•°æ®ä¸€è‡´æ€§
- åŒä¸€æ•°æ®åœ¨ä¸åŒä½ç½®å¼•ç”¨æ˜¯å¦ä¸€è‡´
- åˆè®¡æ•°æ˜¯å¦ç­‰äºåˆ†é¡¹ä¹‹å’Œ
- ç™¾åˆ†æ¯”ç›¸åŠ æ˜¯å¦ä¸º100%
- å›¾è¡¨æ•°æ®ä¸æ­£æ–‡æè¿°æ˜¯å¦ä¸€è‡´

### 4. å¼•ç”¨ä¸ä¾èµ–
- å¼•ç”¨çš„ç« èŠ‚/å›¾è¡¨æ˜¯å¦å­˜åœ¨
- å¼•ç”¨ç¼–å·æ˜¯å¦æ­£ç¡®
- äº¤å‰å¼•ç”¨æ˜¯å¦æœ‰æ•ˆ
- å‚è€ƒæ–‡çŒ®æ˜¯å¦å®Œæ•´

### 5. ç»“æ„é€»è¾‘
- ç« èŠ‚é¡ºåºæ˜¯å¦åˆç†
- æ˜¯å¦å­˜åœ¨å†…å®¹é‡å¤
- é€’è¿›å…³ç³»æ˜¯å¦æ­£ç¡®
- æ€»ç»“æ˜¯å¦æ¶µç›–æ­£æ–‡è¦ç‚¹

## è¯„åˆ†æ ‡å‡†
- 90-100åˆ†ï¼šé€»è¾‘ä¸¥å¯†ï¼Œæ— æ˜æ˜¾çŸ›ç›¾
- 75-89åˆ†ï¼šæœ‰å°çš„é€»è¾‘ç‘•ç–µï¼Œä¸å½±å“ç†è§£
- 60-74åˆ†ï¼šå­˜åœ¨æ˜æ˜¾é€»è¾‘é—®é¢˜ï¼Œéœ€è¦ä¿®æ­£
- 60åˆ†ä»¥ä¸‹ï¼šé€»è¾‘æ··ä¹±ï¼Œéœ€è¦é‡æ–°æ¢³ç†
""",
            CheckDimension.SENSITIVE: """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿¡æ¯å®‰å…¨ä¸åˆè§„å®¡æ ¸ä¸“å®¶ã€‚è¯·å¯¹æ–‡æ¡£è¿›è¡Œ**æ•æ„Ÿä¿¡æ¯å®‰å…¨æ£€æŸ¥**ï¼Œæ‰¾å‡ºé£é™©ç‚¹ã€‚

## æ£€æŸ¥æ¸…å•

### 1. ä¸ªäººèº«ä»½ä¿¡æ¯
- æ˜¯å¦åŒ…å«èº«ä»½è¯å·ç ï¼ˆ18ä½æˆ–15ä½æ•°å­—ï¼‰
- æ˜¯å¦åŒ…å«æ‰‹æœºå·ç ï¼ˆ11ä½æ•°å­—ï¼‰
- æ˜¯å¦åŒ…å«é“¶è¡Œå¡å·
- æ˜¯å¦åŒ…å«è¯¦ç»†ä½å€
- æ˜¯å¦åŒ…å«ç”µå­é‚®ç®±
- æ˜¯å¦åŒ…å«çœŸå®å§“å+å…¶ä»–ä¸ªäººä¿¡æ¯ç»„åˆ

### 2. è´¢åŠ¡æ•æ„Ÿä¿¡æ¯
- æ˜¯å¦åŒ…å«å…·ä½“è–ªèµ„æ•°é¢
- æ˜¯å¦åŒ…å«å…¬å¸è´¢åŠ¡æ•°æ®
- æ˜¯å¦åŒ…å«åˆåŒé‡‘é¢
- æ˜¯å¦åŒ…å«æˆæœ¬/åˆ©æ¶¦ç­‰å•†ä¸šæ•°æ®

### 3. å•†ä¸šæœºå¯†
- æ˜¯å¦åŒ…å«æœªå…¬å¼€çš„äº§å“è®¡åˆ’
- æ˜¯å¦åŒ…å«å†…éƒ¨ç³»ç»Ÿæ¶æ„
- æ˜¯å¦åŒ…å«å®¢æˆ·åå•
- æ˜¯å¦åŒ…å«ç«äº‰å¯¹æ‰‹åˆ†æ
- æ˜¯å¦åŒ…å«æ ¸å¿ƒç®—æ³•/æŠ€æœ¯ç»†èŠ‚

### 4. è´¦å·å¯†ç 
- æ˜¯å¦åŒ…å«ç³»ç»Ÿè´¦å·
- æ˜¯å¦åŒ…å«å¯†ç /å¯†é’¥
- æ˜¯å¦åŒ…å«API Key/Token
- æ˜¯å¦åŒ…å«å†…éƒ¨ç³»ç»ŸURL

### 5. ä¸å½“å†…å®¹
- æ˜¯å¦åŒ…å«æ­§è§†æ€§è¨€è®º
- æ˜¯å¦åŒ…å«æ”¿æ²»æ•æ„Ÿå†…å®¹
- æ˜¯å¦åŒ…å«è™šå‡ä¿¡æ¯
- æ˜¯å¦åŒ…å«è´Ÿé¢è¯„ä»·ï¼ˆäººèº«æ”»å‡»ï¼‰

## é£é™©ç­‰çº§è¯´æ˜
- errorï¼ˆé«˜é£é™©ï¼‰ï¼šåŒ…å«æ˜ç¡®çš„æ•æ„Ÿä¿¡æ¯ï¼Œå¿…é¡»åˆ é™¤æˆ–è„±æ•
- warningï¼ˆä¸­é£é™©ï¼‰ï¼šå¯èƒ½åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Œå»ºè®®å¤æ ¸
- infoï¼ˆä½é£é™©ï¼‰ï¼šå­˜åœ¨æ½œåœ¨é£é™©ï¼Œå»ºè®®æ³¨æ„

## è¯„åˆ†æ ‡å‡†
- 90-100åˆ†ï¼šæœªå‘ç°æ•æ„Ÿä¿¡æ¯
- 75-89åˆ†ï¼šæœ‰ä½é£é™©ä¿¡æ¯ï¼Œå»ºè®®æ³¨æ„
- 60-74åˆ†ï¼šå­˜åœ¨ä¸­ç­‰é£é™©ï¼Œéœ€è¦å¤„ç†
- 60åˆ†ä»¥ä¸‹ï¼šæœ‰é«˜é£é™©æ•æ„Ÿä¿¡æ¯ï¼Œå¿…é¡»ç«‹å³å¤„ç†
""",
            CheckDimension.COMPLIANCE: """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åˆè§„å®¡æ ¸ä¸“å®¶ã€‚è¯·å¯¹æ–‡æ¡£è¿›è¡Œ**åˆè§„æ€§æ£€æŸ¥**ï¼Œç¡®ä¿ç¬¦åˆè§„èŒƒè¦æ±‚ã€‚

## æ£€æŸ¥æ¸…å•

### 1. ç‰ˆæƒä¸å¼•ç”¨
- å¼•ç”¨å†…å®¹æ˜¯å¦æ ‡æ³¨æ¥æº
- å›¾ç‰‡æ˜¯å¦æœ‰ç‰ˆæƒè¯´æ˜
- æ•°æ®æ¥æºæ˜¯å¦æ³¨æ˜
- æ˜¯å¦æ¶‰åŠæŠ„è¢­/æœªæˆæƒä½¿ç”¨

### 2. æ ¼å¼è§„èŒƒ
- æ˜¯å¦ç¬¦åˆè¡Œä¸šæ ‡å‡†æ–‡æ¡£æ ¼å¼
- æ˜¯å¦æœ‰å¿…è¦çš„æ–‡æ¡£è¦ç´ ï¼ˆæ ‡é¢˜ã€æ—¥æœŸã€ç‰ˆæœ¬ã€ä½œè€…ï¼‰
- æ˜¯å¦æœ‰ç›®å½•ï¼ˆé•¿æ–‡æ¡£ï¼‰
- æ˜¯å¦æœ‰ä¿®è®¢å†å²

### 3. æ³•å¾‹åˆè§„
- æ˜¯å¦ç¬¦åˆç›¸å…³æ³•å¾‹æ³•è§„è¦æ±‚
- å…è´£å£°æ˜æ˜¯å¦å®Œæ•´
- æ˜¯å¦æœ‰å¿…è¦çš„æˆæƒè¯´æ˜
- éšç§å£°æ˜æ˜¯å¦åˆ°ä½

### 4. ä¸“ä¸šè§„èŒƒ
- æœ¯è¯­ä½¿ç”¨æ˜¯å¦ç¬¦åˆè¡Œä¸šæ ‡å‡†
- åº¦é‡å•ä½æ˜¯å¦ä½¿ç”¨å›½é™…æ ‡å‡†
- æ—¥æœŸæ ¼å¼æ˜¯å¦è§„èŒƒï¼ˆYYYY-MM-DDï¼‰
- æ•°å­—æ ¼å¼æ˜¯å¦è§„èŒƒï¼ˆåƒåˆ†ä½åˆ†éš”ï¼‰

### 5. æ–‡æ¡£ç®¡ç†
- æ˜¯å¦æœ‰æ–‡æ¡£ç¼–å·
- æ˜¯å¦æœ‰ç‰ˆæœ¬å·
- æ˜¯å¦æœ‰ç”Ÿæ•ˆæ—¥æœŸ
- æ˜¯å¦æœ‰å®¡æ ¸äºº/å®¡æ‰¹äºº

## è¯„åˆ†æ ‡å‡†
- 90-100åˆ†ï¼šå®Œå…¨åˆè§„
- 75-89åˆ†ï¼šåŸºæœ¬åˆè§„ï¼Œæœ‰å°çš„æ”¹è¿›ç©ºé—´
- 60-74åˆ†ï¼šå­˜åœ¨åˆè§„é£é™©ï¼Œéœ€è¦å®Œå–„
- 60åˆ†ä»¥ä¸‹ï¼šä¸¥é‡ä¸åˆè§„ï¼Œéœ€è¦å…¨é¢æ•´æ”¹
"""
        }

        base_prompt = prompts.get(dimension, "è¯·å…¨é¢å®¡æ ¸ä»¥ä¸‹æ–‡æ¡£å†…å®¹ã€‚")

        if custom_rules:
            base_prompt += f"\n\n## ğŸ“Œ é¢å¤–æ£€æŸ¥è¦æ±‚ï¼ˆé‡è¦ï¼‰\n{custom_rules}"

        base_prompt += """

## è¾“å‡ºæ ¼å¼è¦æ±‚

è¯·ä»¥ JSON æ ¼å¼è¿”å›æ£€æµ‹ç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{
    "score": 85,
    "summary": "æ•´ä½“æ£€æµ‹æ€»ç»“ï¼ˆ50å­—ä»¥å†…ï¼‰",
    "issues": [
        {
            "severity": "error",
            "location": "ç¬¬Xæ®µ/ç¬¬Xç« /æ ‡é¢˜X",
            "description": "å…·ä½“é—®é¢˜æè¿°",
            "suggestion": "ä¿®æ”¹å»ºè®®"
        },
        {
            "severity": "warning",
            "location": "å…·ä½“ä½ç½®",
            "description": "é—®é¢˜æè¿°",
            "suggestion": "æ”¹è¿›å»ºè®®"
        }
    ]
}

## ä¸¥é‡ç¨‹åº¦è¯´æ˜
- errorï¼ˆé”™è¯¯ï¼‰ï¼šå¿…é¡»ä¿®æ”¹çš„ä¸¥é‡é—®é¢˜
- warningï¼ˆè­¦å‘Šï¼‰ï¼šå»ºè®®ä¿®æ”¹çš„é—®é¢˜
- infoï¼ˆæç¤ºï¼‰ï¼šå¯ä»¥æ”¹è¿›çš„å°é—®é¢˜

## æ³¨æ„äº‹é¡¹
1. æ¯ä¸ªé—®é¢˜å¿…é¡»æŒ‡å‡º**å…·ä½“ä½ç½®**ï¼Œå¦‚"ç¬¬3æ®µ"ã€"è¡¨æ ¼2"ã€"1.2èŠ‚"
2. é—®é¢˜æè¿°è¦**å…·ä½“æ˜ç¡®**ï¼ŒæŒ‡å‡ºå“ªé‡Œæœ‰é—®é¢˜
3. ä¿®æ”¹å»ºè®®è¦**å¯æ“ä½œ**ï¼Œå‘Šè¯‰ç”¨æˆ·å¦‚ä½•ä¿®æ”¹
4. æ ¹æ®é—®é¢˜æ•°é‡å’Œä¸¥é‡ç¨‹åº¦åˆç†æ‰“åˆ†

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""
        return base_prompt

    def _parse_result(self, response: str, dimension: CheckDimension) -> CheckResult:
        """è§£æ AI è¿”å›çš„ç»“æœ"""
        try:
            # å°è¯•æå– JSON
            response = response.strip()

            # å¤„ç† markdown ä»£ç å—
            if "```" in response:
                # æ‰¾åˆ° JSON å†…å®¹
                import re
                json_match = re.search(r'```(?:json)?\s*([\s\S]*?)```', response)
                if json_match:
                    response = json_match.group(1).strip()

            # å°è¯•æ‰¾åˆ° JSON å¯¹è±¡
            start_idx = response.find('{')
            end_idx = response.rfind('}')
            if start_idx != -1 and end_idx != -1:
                response = response[start_idx:end_idx + 1]

            data = json.loads(response)

            issues = []
            for issue_data in data.get("issues", []):
                # è§£æä¸¥é‡ç¨‹åº¦ï¼Œæä¾›é»˜è®¤å€¼
                severity_str = issue_data.get("severity", "info").lower()
                if severity_str not in ["error", "warning", "info"]:
                    severity_str = "info"

                issues.append(Issue(
                    dimension=dimension,
                    severity=Severity(severity_str),
                    location=issue_data.get("location", "æœªæŒ‡å®šä½ç½®"),
                    description=issue_data.get("description", ""),
                    suggestion=issue_data.get("suggestion", "")
                ))

            # è®¡ç®—åˆç†çš„åˆ†æ•°
            score = float(data.get("score", 80))
            # ç¡®ä¿åˆ†æ•°åœ¨åˆç†èŒƒå›´å†…
            score = max(0, min(100, score))

            # å¦‚æœæœ‰é—®é¢˜ä½†åˆ†æ•°è¿‡é«˜ï¼Œé€‚å½“è°ƒæ•´
            if issues:
                error_count = sum(1 for i in issues if i.severity == Severity.ERROR)
                warning_count = sum(1 for i in issues if i.severity == Severity.WARNING)

                # æ ¹æ®é—®é¢˜æ•°é‡è°ƒæ•´æœ€é«˜åˆ†
                max_score = 100 - (error_count * 10) - (warning_count * 5)
                score = min(score, max_score)

            return CheckResult(
                dimension=dimension,
                score=score,
                summary=data.get("summary", "æ£€æµ‹å®Œæˆ"),
                issues=issues
            )
        except json.JSONDecodeError as e:
            # JSON è§£æå¤±è´¥
            return CheckResult(
                dimension=dimension,
                score=70,
                summary=f"æ£€æµ‹å®Œæˆï¼Œä½†ç»“æœæ ¼å¼å¼‚å¸¸",
                issues=[Issue(
                    dimension=dimension,
                    severity=Severity.INFO,
                    location="ç³»ç»Ÿ",
                    description=f"AI è¿”å›ç»“æœè§£æå¼‚å¸¸: {str(e)[:100]}",
                    suggestion="å»ºè®®é‡æ–°æ£€æµ‹"
                )]
            )
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸
            return CheckResult(
                dimension=dimension,
                score=70,
                summary=f"æ£€æµ‹è¿‡ç¨‹å‡ºç°å¼‚å¸¸",
                issues=[Issue(
                    dimension=dimension,
                    severity=Severity.WARNING,
                    location="ç³»ç»Ÿ",
                    description=f"æ£€æµ‹å¼‚å¸¸: {str(e)[:100]}",
                    suggestion="å»ºè®®é‡æ–°æ£€æµ‹æˆ–è”ç³»ç®¡ç†å‘˜"
                )]
            )


class OpenAIProvider(BaseAIProvider):
    """OpenAI å®ç°"""

    def __init__(self):
        from openai import AsyncOpenAI
        settings = get_settings()
        self.client = AsyncOpenAI(
            api_key=settings.openai_api_key,
            base_url=settings.openai_base_url
        )
        self.model = settings.openai_model

    async def analyze(
        self,
        content: str,
        dimension: CheckDimension,
        custom_rules: Optional[str] = None
    ) -> CheckResult:
        prompt = self._get_dimension_prompt(dimension, custom_rules)

        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": f"è¯·æ£€æµ‹ä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼š\n\n{content}"}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )

        result_text = response.choices[0].message.content
        return self._parse_result(result_text, dimension)

    async def generate_summary(
        self,
        content: str,
        results: List[CheckResult]
    ) -> str:
        # ç»Ÿè®¡é—®é¢˜æ•°é‡
        total_errors = sum(sum(1 for i in r.issues if i.severity == Severity.ERROR) for r in results)
        total_warnings = sum(sum(1 for i in r.issues if i.severity == Severity.WARNING) for r in results)
        total_infos = sum(sum(1 for i in r.issues if i.severity == Severity.INFO) for r in results)
        avg_score = sum(r.score for r in results) / len(results) if results else 0

        results_text = "\n".join([
            f"- {r.dimension.value}: å¾—åˆ† {r.score:.0f}åˆ†, {r.summary}"
            for r in results
        ])

        stats_text = f"é—®é¢˜ç»Ÿè®¡ï¼šé”™è¯¯ {total_errors} ä¸ªï¼Œè­¦å‘Š {total_warnings} ä¸ªï¼Œæç¤º {total_infos} ä¸ªï¼Œå¹³å‡å¾—åˆ† {avg_score:.0f} åˆ†"

        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£å®¡æ ¸ä¸“å®¶ã€‚è¯·æ ¹æ®æ£€æµ‹ç»“æœç”Ÿæˆç®€æ´çš„æ•´ä½“è¯„ä¼°æ€»ç»“ã€‚
è¦æ±‚ï¼š1.ç»™å‡ºæ•´ä½“è¯„ä»· 2.æŒ‡å‡ºä¸»è¦é—®é¢˜ 3.ç»™å‡ºæ”¹è¿›å»ºè®® 4.æ§åˆ¶åœ¨150å­—ä»¥å†…"""},
                {"role": "user", "content": f"å„ç»´åº¦æ£€æµ‹ç»“æœï¼š\n{results_text}\n\n{stats_text}"}
            ],
            temperature=0.5
        )

        return response.choices[0].message.content


class AnthropicProvider(BaseAIProvider):
    """Anthropic Claude å®ç°"""

    def __init__(self):
        from anthropic import AsyncAnthropic
        settings = get_settings()
        self.client = AsyncAnthropic(api_key=settings.anthropic_api_key)
        self.model = settings.anthropic_model

    async def analyze(
        self,
        content: str,
        dimension: CheckDimension,
        custom_rules: Optional[str] = None
    ) -> CheckResult:
        prompt = self._get_dimension_prompt(dimension, custom_rules)

        response = await self.client.messages.create(
            model=self.model,
            max_tokens=4096,
            messages=[
                {"role": "user", "content": f"{prompt}\n\nè¯·æ£€æµ‹ä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼š\n\n{content}"}
            ]
        )

        result_text = response.content[0].text
        return self._parse_result(result_text, dimension)

    async def generate_summary(
        self,
        content: str,
        results: List[CheckResult]
    ) -> str:
        total_errors = sum(sum(1 for i in r.issues if i.severity == Severity.ERROR) for r in results)
        total_warnings = sum(sum(1 for i in r.issues if i.severity == Severity.WARNING) for r in results)
        avg_score = sum(r.score for r in results) / len(results) if results else 0

        results_text = "\n".join([
            f"- {r.dimension.value}: å¾—åˆ† {r.score:.0f}åˆ†, {r.summary}"
            for r in results
        ])

        stats_text = f"é—®é¢˜ç»Ÿè®¡ï¼šé”™è¯¯ {total_errors} ä¸ªï¼Œè­¦å‘Š {total_warnings} ä¸ªï¼Œå¹³å‡å¾—åˆ† {avg_score:.0f} åˆ†"

        response = await self.client.messages.create(
            model=self.model,
            max_tokens=1024,
            messages=[
                {"role": "user", "content": f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£å®¡æ ¸ä¸“å®¶ã€‚è¯·æ ¹æ®æ£€æµ‹ç»“æœç”Ÿæˆç®€æ´çš„æ•´ä½“è¯„ä¼°æ€»ç»“ï¼ˆ150å­—ä»¥å†…ï¼‰ï¼ŒåŒ…æ‹¬æ•´ä½“è¯„ä»·ã€ä¸»è¦é—®é¢˜ã€æ”¹è¿›å»ºè®®ã€‚\n\nå„ç»´åº¦æ£€æµ‹ç»“æœï¼š\n{results_text}\n\n{stats_text}"}
            ]
        )

        return response.content[0].text


class QwenProvider(BaseAIProvider):
    """é€šä¹‰åƒé—®å®ç°ï¼ˆä½¿ç”¨ OpenAI å…¼å®¹æ¥å£ï¼‰"""

    def __init__(self):
        from openai import AsyncOpenAI
        settings = get_settings()
        self.client = AsyncOpenAI(
            api_key=settings.qwen_api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
        )
        self.model = settings.qwen_model

    async def analyze(
        self,
        content: str,
        dimension: CheckDimension,
        custom_rules: Optional[str] = None
    ) -> CheckResult:
        prompt = self._get_dimension_prompt(dimension, custom_rules)

        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": f"è¯·æ£€æµ‹ä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼š\n\n{content}"}
            ],
            temperature=0.3
        )

        result_text = response.choices[0].message.content
        return self._parse_result(result_text, dimension)

    async def generate_summary(
        self,
        content: str,
        results: List[CheckResult]
    ) -> str:
        total_errors = sum(sum(1 for i in r.issues if i.severity == Severity.ERROR) for r in results)
        total_warnings = sum(sum(1 for i in r.issues if i.severity == Severity.WARNING) for r in results)
        total_infos = sum(sum(1 for i in r.issues if i.severity == Severity.INFO) for r in results)
        avg_score = sum(r.score for r in results) / len(results) if results else 0

        results_text = "\n".join([
            f"- {r.dimension.value}: å¾—åˆ† {r.score:.0f}åˆ†, {r.summary}"
            for r in results
        ])

        stats_text = f"é—®é¢˜ç»Ÿè®¡ï¼šé”™è¯¯ {total_errors} ä¸ªï¼Œè­¦å‘Š {total_warnings} ä¸ªï¼Œæç¤º {total_infos} ä¸ªï¼Œå¹³å‡å¾—åˆ† {avg_score:.0f} åˆ†"

        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£å®¡æ ¸ä¸“å®¶ã€‚è¯·æ ¹æ®æ£€æµ‹ç»“æœç”Ÿæˆç®€æ´çš„æ•´ä½“è¯„ä¼°æ€»ç»“ã€‚
è¦æ±‚ï¼š1.ç»™å‡ºæ•´ä½“è¯„ä»· 2.æŒ‡å‡ºä¸»è¦é—®é¢˜ 3.ç»™å‡ºæ”¹è¿›å»ºè®® 4.æ§åˆ¶åœ¨150å­—ä»¥å†…"""},
                {"role": "user", "content": f"å„ç»´åº¦æ£€æµ‹ç»“æœï¼š\n{results_text}\n\n{stats_text}"}
            ],
            temperature=0.5
        )

        return response.choices[0].message.content


def get_ai_provider(provider_name: Optional[str] = None) -> BaseAIProvider:
    """è·å– AI æä¾›å•†å®ä¾‹"""
    settings = get_settings()
    provider = provider_name or settings.default_ai_provider

    if provider == "openai":
        return OpenAIProvider()
    elif provider == "anthropic":
        try:
            # å…ˆæµ‹è¯•èƒ½å¦å¯¼å…¥
            import anthropic
            return AnthropicProvider()
        except ImportError:
            raise ValueError("anthropic æ¨¡å—æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install anthropicï¼Œæˆ–é€‰æ‹©å…¶ä»– AI æä¾›å•†")
    elif provider == "qwen":
        return QwenProvider()
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ AI æä¾›å•†: {provider}ï¼Œå¯é€‰: openai, anthropic, qwen")
